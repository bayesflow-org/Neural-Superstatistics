{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from functools import partial\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMD Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum_mean_discrepancy(source_samples, target_samples, minimum=0., unbiased=False):\n",
    "    \"\"\" This Maximum Mean Discrepancy (MMD) loss is calculated with a number of different Gaussian kernels.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    sigmas = [\n",
    "        1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 15, 20, 25, 30, 35, 100,\n",
    "        1e3, 1e4, 1e5, 1e6\n",
    "    ]\n",
    "    gaussian_kernel = partial(_gaussian_kernel_matrix, sigmas=sigmas)\n",
    "    if unbiased:\n",
    "        loss_value = _mmd_kernel_unbiased(source_samples, target_samples, kernel=gaussian_kernel)\n",
    "    else:\n",
    "        loss_value = _mmd_kernel(source_samples, target_samples, kernel=gaussian_kernel)\n",
    "        \n",
    "        \n",
    "    loss_value = tf.maximum(minimum, loss_value) \n",
    "    return loss_value\n",
    "\n",
    "def _gaussian_kernel_matrix(x, y, sigmas):\n",
    "    \"\"\" Computes a Gaussian Radial Basis Kernel between the samples of x and y.\n",
    "\n",
    "    We create a sum of multiple gaussian kernels each having a width :math:`\\sigma_i`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x :  tf.Tensor of shape (M, num_features)\n",
    "    y :  tf.Tensor of shape (N, num_features)\n",
    "    sigmas : list(float)\n",
    "        List which denotes the widths of each of the gaussians in the kernel.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    kernel: tf.Tensor\n",
    "        RBF kernel of shape [num_samples{x}, num_samples{y}]\n",
    "    \"\"\"\n",
    "    def norm(v):\n",
    "        return tf.reduce_sum(tf.square(v), 1)\n",
    "    beta = 1. / (2. * (tf.expand_dims(sigmas, 1)))\n",
    "    dist = tf.transpose(norm(tf.expand_dims(x, 2) - tf.transpose(y)))\n",
    "    s = tf.matmul(beta, tf.reshape(dist, (1, -1)))\n",
    "    kernel = tf.reshape(tf.reduce_sum(tf.exp(-s), 0), tf.shape(dist))\n",
    "    return kernel\n",
    "\n",
    "def _mmd_kernel(x, y, kernel=_gaussian_kernel_matrix):\n",
    "    \"\"\" Computes the Maximum Mean Discrepancy (MMD) of two samples: x and y.\n",
    "\n",
    "    Maximum Mean Discrepancy (MMD) is a distance-measure between the samples of the distributions of x and y.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x      : tf.Tensor of shape (num_samples, num_features)\n",
    "    y      : tf.Tensor of shape (num_samples, num_features)\n",
    "    kernel : callable, default: _gaussian_kernel_matrix\n",
    "        A function which computes the kernel in MMD.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : tf.Tensor\n",
    "        squared maximum mean discrepancy loss, shape (,)\n",
    "    \"\"\"\n",
    "\n",
    "    loss = tf.reduce_mean(kernel(x, x))  # lint error: sigmas unfilled\n",
    "    loss += tf.reduce_mean(kernel(y, y))  # lint error: sigmas unfilled\n",
    "    loss -= 2 * tf.reduce_mean(kernel(x, y))  # lint error: sigmas unfilled\n",
    "    return loss\n",
    "\n",
    "def _mmd_kernel_unbiased(x, y, kernel=_gaussian_kernel_matrix):\n",
    "    \"\"\" Computes the Maximum Mean Discrepancy (MMD) of two samples: x and y.\n",
    "\n",
    "    Maximum Mean Discrepancy (MMD) is a distance-measure between the samples of the distributions of x and y.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x      : tf.Tensor of shape (num_samples, num_features)\n",
    "    y      : tf.Tensor of shape (num_samples, num_features)\n",
    "    kernel : callable, default: _gaussian_kernel_matrix\n",
    "        A function which computes the kernel in MMD.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : tf.Tensor\n",
    "        squared maximum mean discrepancy loss, shape (,)\n",
    "    \"\"\"\n",
    "    m, n = x.shape[0], y.shape[0]\n",
    "    loss = (1.0/(m*(m+1))) * tf.reduce_sum(kernel(x, x))  # lint error: sigmas unfilled\n",
    "    loss += (1.0/(n*(n+1))) * tf.reduce_sum(kernel(y, y))  # lint error: sigmas unfilled\n",
    "    loss -= (2.0/(m*n)) * tf.reduce_sum(kernel(x, y))  # lint error: sigmas unfilled\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmd_permutation(x, y, n_perm=1000, kernel=_gaussian_kernel_matrix, unbiased=False):\n",
    "    \"\"\"\n",
    "    Computes the p-value of the MMD by permuting the samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Obtain sample sizes\n",
    "    m = int(x.shape[0])\n",
    "    n = int(y.shape[0])\n",
    "    xy = tf.concat((x, y), axis=0)\n",
    "    \n",
    "    # Prepare MMD\n",
    "    sigmas = [\n",
    "        1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 15, 20, 25, 30, 35, 100,\n",
    "        1e3, 1e4, 1e5, 1e6\n",
    "    ]\n",
    "    gaussian_kernel = partial(_gaussian_kernel_matrix, sigmas=sigmas)\n",
    "    mmd2_null = np.zeros(n_perm)\n",
    "    \n",
    "    # Run permutations\n",
    "    for i in range(n_perm):\n",
    "        idx = np.random.permutation(m+n)\n",
    "        xy = tf.gather(xy, idx, axis=0)\n",
    "        if unbiased:\n",
    "            mmd2 = _mmd_kernel_unbiased(xy[:m], xy[m:], kernel=gaussian_kernel)\n",
    "        else:\n",
    "            mmd2 = _mmd_kernel(xy[:m], xy[m:], kernel=gaussian_kernel)\n",
    "        mmd2_null[i] = mmd2\n",
    "    return mmd2_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rt_fast_dm = np.load(\"../saved_arrays/pred_rt_fast_dm.npy\")\n",
    "pred_rt_neural = np.load(\"../saved_arrays/gpddm_pred_rt_neural.npy\")\n",
    "emp_rt = np.load(\"../saved_arrays/emp_rt_joint.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data structures\n",
    "n_sub = emp_rt.shape[0]\n",
    "n_sim = pred_rt_neural.shape[1]\n",
    "n_perm = 1000\n",
    "\n",
    "mmd_dynamic_emp = np.empty((n_sub, n_sim), dtype=np.float32)\n",
    "mmd_dynamic_emp_perm = np.empty((n_sub, n_sim, n_perm), dtype=np.float32)\n",
    "\n",
    "mmd_dynamic_fast = np.empty((n_sub, n_sim), dtype=np.float32)\n",
    "mmd_dynamic_fast_perm = np.empty((n_sub, n_sim, n_perm), dtype=np.float32)\n",
    "\n",
    "mmd_fast_emp = np.empty(n_sub, dtype=np.float32)\n",
    "mmd_fast_emp_perm = np.empty((n_sub, n_perm), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over persons\n",
    "for sub in range(n_sub):\n",
    "    # subset person empirical data and fast-dm prediction\n",
    "    x_fast_dm = np.atleast_2d(pred_rt_fast_dm[sub]).T.astype(np.float32)\n",
    "    x_emp = np.atleast_2d(emp_rt[sub]).T.astype(np.float32)\n",
    "\n",
    "    # calculate mmd and permutation between emp and fast-dm\n",
    "    mmd_fast_emp[sub] = maximum_mean_discrepancy(x_fast_dm, x_emp)\n",
    "    # mmd_fast_emp_perm[i] = mmd_permutation(x_fast_dm, x_emp)\n",
    "\n",
    "    for sim in range(n_sim):\n",
    "        # subset prediction of dynamic model\n",
    "        x_dynamic = np.atleast_2d(pred_rt_neural[sub, sim]).T.astype(np.float32)\n",
    "\n",
    "        # calculate mmd and permutation between dynamic and emp\n",
    "        mmd_dynamic_emp[sub, sim] = maximum_mean_discrepancy(x_dynamic, x_emp)\n",
    "        # mmd_dynamic_emp_perm[i, j] = mmd_permutation(x_dynamic, x_emp)\n",
    "\n",
    "        # calculate mmd and permutation between dynamic and fast-dm\n",
    "        mmd_dynamic_fast[sub, sim] = maximum_mean_discrepancy(x_dynamic, x_fast_dm)\n",
    "        # mmd_dynamic_fast_perm[i, j] = mmd_permutation(x_dynamic, x_fast_dm)\n",
    "        \n",
    "    print(\"Calculation for Subject {} has finished...\".format(sub+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_dynamic_emp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_dynamic_emp.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_fast_emp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_fast_emp.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_dynamic_fast.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_dynamic_fast.std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c85bf36f462aee8672315966a66dd5e91fa71003ac562e7969aa481cd7b291c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
